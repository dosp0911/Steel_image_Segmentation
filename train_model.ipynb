{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIh8jBqI1xNS"
   },
   "source": [
    "### TODO :\n",
    "\n",
    " 1. Mask maximum value index & Initial values of weights check\n",
    " 2. Convert input 3ch image to gray and first layer input channel of the model \n",
    " 3. accuacry metric change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wE5P6a1S1xNU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# import import_ipynb\n",
    "from steel_dataset import Steel_dataset\n",
    "from model import U_net\n",
    "from util import csv_file_load\n",
    "import util\n",
    "from pre_processing import Pre_process_img\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30dyiPi21xNY"
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = pathlib.Path('steel_images')\n",
    "# ROOT_PATH = pathlib.Path('.')\n",
    "IMG_FILE_PATH = ROOT_PATH / 'train_images'\n",
    "TRAIN_FILE = ROOT_PATH / 'train.csv'\n",
    "CK_PATH = ROOT_PATH / 'checkpoints'\n",
    "LOG_PATH = ROOT_PATH / 'logs'\n",
    "\n",
    "SPILIT_RATIO = 0.8\n",
    "n_batch = 4\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0iE0WDk1xNb"
   },
   "outputs": [],
   "source": [
    "train_pd = csv_file_load(TRAIN_FILE)\n",
    "# train_pd.ClassId = 1\n",
    "train_idx = int(len(train_pd) * SPILIT_RATIO)\n",
    "\n",
    "val_pd = train_pd.iloc[train_idx:, :].reset_index(drop=True)\n",
    "train_pd = train_pd.iloc[:train_idx, :]\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tw7DCFse1xNe"
   },
   "outputs": [],
   "source": [
    "train_dataset = Steel_dataset(IMG_FILE_PATH, train_pd, out_size=(132, 1476))\n",
    "val_dataset = Steel_dataset(IMG_FILE_PATH, val_pd, out_size=(132, 1476))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBIlR50x1xNj"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=n_batch, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=n_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBomvXDf1xNm"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'in_channel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cdf580c83284>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Initialize weights of U-net model with normal distribution std = sqrt(2/N), N = the number of incomding Nodes of one neuron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# ex) 3x3 convd with 64 channels in previous layer -> N = 9 * 64 = 576\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'in_channel'"
     ]
    }
   ],
   "source": [
    "u_net = U_net(n_classes=n_classes, in_channel= n_classes).to(device)\n",
    "# Initialize weights of U-net model with normal distribution std = sqrt(2/N), N = the number of incomding Nodes of one neuron\n",
    "# ex) 3x3 convd with 64 channels in previous layer -> N = 9 * 64 = 576 \n",
    "for p in u_net.parameters():\n",
    "  nn.init.normal_(p, std= math.sqrt(2/p[0].numel())) \n",
    "\n",
    "  \n",
    "# Xavier initialize   \n",
    "# for p in u_net.parameters():\n",
    "#   nn.init.xavier_normal_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1585419118147,
     "user": {
      "displayName": "dongsup kim",
      "photoUrl": "",
      "userId": "13436176985677928979"
     },
     "user_tz": -540
    },
    "id": "AbnZWUfLT44V",
    "outputId": "50ec328b-a8d4-4da5-883f-705a5f393785"
   },
   "outputs": [],
   "source": [
    "u_net = U_net(n_classes=n_classes)\n",
    "o = u_net(train_dataset[0][0].unsqueeze(dim=0))\n",
    "# import matplotlib.pyplot as plt\n",
    "# o.squeeze().permute(1,2,0).unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 132, 1476])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:,3,:,:].squeeze(dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaPZ0e9P1xNz"
   },
   "outputs": [],
   "source": [
    "def save_model(model, optim, save_path, epoch, loss):\n",
    "  torch.save({\n",
    "        'model' : model,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss' : loss,\n",
    "        'optim_state_dict': optim.state_dict()\n",
    "    }, save_path)\n",
    "  print(f'model saved \\n {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights_by_pixel_frequencies(classId, EncodedPixels, img_size):\n",
    "  '''\n",
    "     img_size must be 1 dimension. (H*W)\n",
    "  '''\n",
    "  p_counts = np.zeros(len(classId.unique())+1)\n",
    "  \n",
    "  # 0 is for background\n",
    "  # other than 0 is for foreground\n",
    "  u_classId = list(classId.unique())\n",
    "  u_classId.append(0)\n",
    "  \n",
    "  # counts total pixels of training image dataset\n",
    "  for c, e in zip(classId, EncodedPixels):\n",
    "    rlc = np.asarray(e.split(' '))\n",
    "    cls_pixels = sum(rlc[1::2].astype(int))\n",
    "    p_counts[c] += cls_pixels\n",
    "    p_counts[0] += img_size - cls_pixels \n",
    "  p_counts /= img_size\n",
    "    \n",
    "  return util.get_weights_ratio_over_frequnecies(p_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weight\n",
    " : class weight need to be adding the context(spatial variance) of images\n",
    "\n",
    "$ w~(c)~ = w~0~ + w~(context)~ $ \n",
    "\n",
    "$ Loss = -\\sum w(c) * p(x) * log(p(x)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6619,
     "status": "ok",
     "timestamp": 1585398218907,
     "user": {
      "displayName": "dongsup kim",
      "photoUrl": "",
      "userId": "13436176985677928979"
     },
     "user_tz": -540
    },
    "id": "pZMcMD3a1xN1",
    "outputId": "08df56bf-7f21-4909-849a-852de1eeb23f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00018669895161934006, 0.1309006771936889, 0.6234398782343988, 0.0039001194268747843, 0.01847140301219158]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weight = get_class_weights_by_pixel_frequencies(train_pd.ClassId, train_pd.EncodedPixels, 1600*256)\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoOTUujd1xN4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight= class_weight)\n",
    "optim = torch.optim.SGD(u_net.parameters(), momentum=0.99, lr=0.001)\n",
    "writer = SummaryWriter(LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Piq4v6ea5bYL"
   },
   "outputs": [],
   "source": [
    "train_len=len(train_dataset)\n",
    "val_len=len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10328353,
     "status": "error",
     "timestamp": 1585418499199,
     "user": {
      "displayName": "dongsup kim",
      "photoUrl": "",
      "userId": "13436176985677928979"
     },
     "user_tz": -540
    },
    "id": "W94eJagl1xN8",
    "outputId": "c190f1f8-1806-4120-c363-63b2077f06af"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "total_acc_train = 0.0\n",
    "total_acc_val = 0.0\n",
    "total_loss_val = 0.0\n",
    "total_loss_train = 0.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  total_acc_train = 0.0\n",
    "  total_acc_val = 0.0\n",
    "  total_loss_val = 0.0\n",
    "  total_loss_train = 0.0\n",
    "\n",
    "  for i, (x_, mask) in enumerate(train_dataloader):\n",
    "    x_ = x_.cuda()\n",
    "    mask = mask.cuda().long()\n",
    "    \n",
    "    optim.zero_grad()\n",
    "\n",
    "    out = u_net(x_)\n",
    "    loss_train = criterion(out, mask)\n",
    "    loss_train.backward()\n",
    "    optim.step()\n",
    "\n",
    "    total_acc_train += (torch.argmax(out, dim=1).squeeze() == mask).sum() / float(out.numel())\n",
    "    total_loss_train += loss_train\n",
    "\n",
    "    if i%100 == 0 :\n",
    "      writer.add_scalars('train',{'accuracy': total_acc_train/i, 'loss' : total_loss_train})\n",
    "      print(f'epoch:{epoch} train batch : {i/train_len * 100}% ---- \\n train_loss:{total_loss_train / i} \\\n",
    "                        train_accuracy:{total_acc_train / i }')\n",
    "\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    for j, (val_x, val_mask) in enumerate(val_dataloader):\n",
    "      val_x = val_x.cuda()\n",
    "      val_mask = val_mask.cuda().long()\n",
    "      out_val = u_net(val_x)\n",
    "      loss_val = criterion(out_val, val_mask)\n",
    "\n",
    "      total_acc_val += (torch.argmax(out_val, dim=1).squeeze() == val_mask).sum() / float(out_val.numel())\n",
    "      total_loss_val += loss_val\n",
    "\n",
    "      if j%100 == 0:\n",
    "        print(f'epoch:{epoch} val_batch : {j/val_len * 100}% ---- \\n val_loss:{total_loss_val / j} \\\n",
    "                        val_accuracy:{total_acc_val / j}')\n",
    "      if j == val_len:\n",
    "        # display output images of each classes\n",
    "        for k in range(len(n_classes)):\n",
    "          g = make_grid(out_val[:,k,:,:].squeeze(dim=1))\n",
    "          writer.add_images(f'val_output class{k+1}', g)\n",
    "        # display class names of each images\n",
    "        val_cls = [int(val_mask[l].unique()[1]) for l in range(len(val_mask))]\n",
    "        m_g = mask_grid(val_mask.unsqueeze(dim=1))\n",
    "        writer.add_images(f'val_mask class {val_cls})', m_g.squeeze(dim=1), dataformats='HW')\n",
    "        \n",
    "  writer.add_scalars('val',{'accuracy': total_acc_val/val_len, 'loss': total_loss_val}) \n",
    "  print(f'epoch:{epoch} ended. \\n -- total_val_loss:{total_loss_val} total_val_accuracy:{total_acc_val}')        \n",
    "    \n",
    "  save_model(u_net, optim, f'u_net_{epoch}e_{int(total_loss_val)}l.pt', epoch, total_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 125, 125])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = torch.rand((4,3,125,125))\n",
    "g = make_grid(mm)\n",
    "mm.size()\n",
    "\n",
    "# for i in range(5):\n",
    "#   g = make_grid(o[:,i,:,:].squeeze(dim=1))\n",
    "#   writer.add_images(f'val_output class{i+1}', g, dataformats='CHW')\n",
    "#   writer.add_image(f'val_mask class {int(train_dataset[0][1].unique()[1])}', train_dataset[0][1], dataformats='HW')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
