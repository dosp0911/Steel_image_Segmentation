{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO :\n",
    "1. load data \n",
    " - standardize images\n",
    " - split into train/val sets\n",
    "2. load model\n",
    "3. Loss function\n",
    " - cross entropy\n",
    "4. optimization\n",
    " - SGD(momentum=0.99, learning_rate=0.01)\n",
    " - optimizer.zero_grad()\n",
    "5. metrics(loss, accuracy)\n",
    " - each of train/val\n",
    "6. save models and logs in middle of train\n",
    "7. train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# import import_ipynb\n",
    "from steel_dataset import Steel_dataset\n",
    "from model import U_net\n",
    "from util import csv_file_load\n",
    "\n",
    "from pre_processing import Pre_process_img\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = pathlib.Path('severstal-steel-defect-detection')\n",
    "IMG_FILE_PATH = ROOT_PATH / 'train_images'\n",
    "TRAIN_FILE = ROOT_PATH / 'train.csv'\n",
    "CK_PATH = pathlib.Path('checkpoints')\n",
    "\n",
    "SPILIT_RATIO = 0.2\n",
    "n_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = csv_file_load(TRAIN_FILE)\n",
    "val_idx = int(len(train_pd) * SPILIT_RATIO)\n",
    "\n",
    "train_pd, val_pd = train_pd.iloc[:val_idx, :], train_pd.iloc[val_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Steel_dataset(IMG_FILE_PATH, train_pd, out_size=(132, 1476))\n",
    "val_dataset = Steel_dataset(IMG_FILE_PATH, val_pd, out_size=(132, 1476))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=n_batch, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=n_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "u_net = U_net(n_classes=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = u_net(train_dataset[0][0].unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.05975341796875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.core.debugger import set_trace\n",
    "# set_trace()\n",
    "(train_dataset[0][0].numel() + train_dataset[0][1] .numel()) * 3 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].size() == train_dataset[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optim, save_path, epoch, loss):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss' : loss,\n",
    "        'optim_state_dict': optim.state_dict()\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  4 71 10]\n"
     ]
    }
   ],
   "source": [
    "class_weight = np.array((train_pd.groupby('ClassId').count().apply(lambda x: x/x.sum() ).iloc[:,0]*100).astype(int))\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(u_net.parameters(), momentum=0.99, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-15-63dd1895c2a0>\u001b[0m(9)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      7 \u001b[1;33m        \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m        \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 9 \u001b[1;33m        \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     11 \u001b[1;33m        \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-15-63dd1895c2a0>\u001b[0m(11)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      9 \u001b[1;33m        \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 11 \u001b[1;33m        \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     13 \u001b[1;33m        \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final: torch.Size([1, 5, 132, 1476])\n",
      "> \u001b[1;32m<ipython-input-15-63dd1895c2a0>\u001b[0m(12)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     10 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     11 \u001b[1;33m        \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 12 \u001b[1;33m        \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     13 \u001b[1;33m        \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     14 \u001b[1;33m        \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-15-63dd1895c2a0>\u001b[0m(13)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     11 \u001b[1;33m        \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 13 \u001b[1;33m        \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     14 \u001b[1;33m        \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     15 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 2.00 GiB total capacity; 1.10 GiB already allocated; 114.50 MiB free; 1.18 GiB reserved in total by PyTorch)\n",
      "> \u001b[1;32m<ipython-input-15-63dd1895c2a0>\u001b[0m(13)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     11 \u001b[1;33m        \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 13 \u001b[1;33m        \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     14 \u001b[1;33m        \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     15 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  out.element_size()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for i, (x_, mask) in enumerate(train_dataloader):\n",
    "        x_ = x_.cuda()\n",
    "        mask = mask.cuda().long()\n",
    "        from IPython.core.debugger import set_trace\n",
    "        set_trace()\n",
    "        optim.zero_grad()\n",
    "      \n",
    "        out = u_net(x_)\n",
    "        loss_train = criterion(out, mask)\n",
    "        loss_train.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j, (val_x, val_mask) in enumerate(val_dataloader):\n",
    "            out_val = u_net(val_x)\n",
    "            loss_val = criterion(out_val, val_mask)\n",
    "            \n",
    "    print(f'epoch:{epoch} batch:{i}th \\n -- train_loss:{loss_train} \\\n",
    "                        train_accuracy:{(torch.argmax(out, dim=1).squeeze() == mask).sum() / float(out.numel()) * 100}')\n",
    "    \n",
    "    print(f'epoch:{epoch} batch:{i}th \\n -- val_loss:{loss_val} \\\n",
    "                          train_accuracy:{(torch.argmax(out_val, dim=1).squeeze() == val_mask).sum() / float(out_val.numel()) * 100}')        \n",
    "    \n",
    "    save_model(u_net, optim, CK_PATH / f'u_net_{epoch}e_{int(loss_val)}l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:cont_layer1.c_conv11.weight size:torch.Size([64, 3, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer1.c_conv11.bias size:torch.Size([64]) dtype:torch.float32\n",
      "name:cont_layer1.c_conv12.weight size:torch.Size([64, 64, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer1.c_conv12.bias size:torch.Size([64]) dtype:torch.float32\n",
      "name:cont_layer2.c_conv21.weight size:torch.Size([128, 64, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer2.c_conv21.bias size:torch.Size([128]) dtype:torch.float32\n",
      "name:cont_layer2.c_conv22.weight size:torch.Size([128, 128, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer2.c_conv22.bias size:torch.Size([128]) dtype:torch.float32\n",
      "name:cont_layer3.c_conv31.weight size:torch.Size([256, 128, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer3.c_conv31.bias size:torch.Size([256]) dtype:torch.float32\n",
      "name:cont_layer3.c_conv32.weight size:torch.Size([256, 256, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer3.c_conv32.bias size:torch.Size([256]) dtype:torch.float32\n",
      "name:cont_layer4.c_conv41.weight size:torch.Size([512, 256, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer4.c_conv41.bias size:torch.Size([512]) dtype:torch.float32\n",
      "name:cont_layer4.c_conv42.weight size:torch.Size([512, 512, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer4.c_conv42.bias size:torch.Size([512]) dtype:torch.float32\n",
      "name:cont_layer5.c_conv51.weight size:torch.Size([1024, 512, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer5.c_conv51.bias size:torch.Size([1024]) dtype:torch.float32\n",
      "name:cont_layer5.c_conv52.weight size:torch.Size([1024, 1024, 3, 3]) dtype:torch.float32\n",
      "name:cont_layer5.c_conv52.bias size:torch.Size([1024]) dtype:torch.float32\n",
      "name:exp_layer5.weight size:torch.Size([1024, 512, 2, 2]) dtype:torch.float32\n",
      "name:exp_layer5.bias size:torch.Size([512]) dtype:torch.float32\n",
      "name:exp_layer4.e_conv41.weight size:torch.Size([512, 1024, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer4.e_conv41.bias size:torch.Size([512]) dtype:torch.float32\n",
      "name:exp_layer4.e_conv42.weight size:torch.Size([512, 512, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer4.e_conv42.bias size:torch.Size([512]) dtype:torch.float32\n",
      "name:exp_layer4.e_up_conv4.weight size:torch.Size([512, 256, 2, 2]) dtype:torch.float32\n",
      "name:exp_layer4.e_up_conv4.bias size:torch.Size([256]) dtype:torch.float32\n",
      "name:exp_layer3.e_conv31.weight size:torch.Size([256, 512, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer3.e_conv31.bias size:torch.Size([256]) dtype:torch.float32\n",
      "name:exp_layer3.e_conv32.weight size:torch.Size([256, 256, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer3.e_conv32.bias size:torch.Size([256]) dtype:torch.float32\n",
      "name:exp_layer3.e_up_conv3.weight size:torch.Size([256, 128, 2, 2]) dtype:torch.float32\n",
      "name:exp_layer3.e_up_conv3.bias size:torch.Size([128]) dtype:torch.float32\n",
      "name:exp_layer2.e_conv21.weight size:torch.Size([128, 256, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer2.e_conv21.bias size:torch.Size([128]) dtype:torch.float32\n",
      "name:exp_layer2.e_conv22.weight size:torch.Size([128, 128, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer2.e_conv22.bias size:torch.Size([128]) dtype:torch.float32\n",
      "name:exp_layer2.e_up_conv2.weight size:torch.Size([128, 64, 2, 2]) dtype:torch.float32\n",
      "name:exp_layer2.e_up_conv2.bias size:torch.Size([64]) dtype:torch.float32\n",
      "name:exp_layer1.e_conv11.weight size:torch.Size([64, 128, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer1.e_conv11.bias size:torch.Size([64]) dtype:torch.float32\n",
      "name:exp_layer1.e_conv12.weight size:torch.Size([64, 64, 3, 3]) dtype:torch.float32\n",
      "name:exp_layer1.e_conv12.bias size:torch.Size([64]) dtype:torch.float32\n",
      "name:exp_layer1.e_conv_f.weight size:torch.Size([5, 64, 1, 1]) dtype:torch.float32\n",
      "name:exp_layer1.e_conv_f.bias size:torch.Size([5]) dtype:torch.float32\n",
      "Model size : 124128020 byte -> 118.37770462036133 MiB\n"
     ]
    }
   ],
   "source": [
    "# print(u_net.state_dict())\n",
    "total_ = 0\n",
    "for k, v in u_net.state_dict().items():\n",
    "    print(f'name:{k} size:{v.size()} dtype:{v.dtype}')\n",
    "    total_ += v.numel()\n",
    "print(f'Model size : {total_*4} byte -> {total_*4/1024**2} MiB')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
