{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file_load(f_p, index_col=False ):\n",
    "    if f_p.exists():\n",
    "        return pd.read_csv(f_p, index_col=index_col)\n",
    "    else:\n",
    "        raise FileExistsError(f'{f_p} no exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_to_class_folders(f_names, classes, root_f):\n",
    "    root_path = pathlib.Path(str(root_f))\n",
    "    if not(root_path.exists()):\n",
    "        raise FileExistsError(f'{root_f} does not exist')\n",
    "        \n",
    "    class_dirs = pd.unique(classes).astype('str')\n",
    "    for d in class_dirs:\n",
    "        class_dir = root_path / d\n",
    "        if not class_dir.exists():\n",
    "            class_dir.mkdir()\n",
    "        \n",
    "    for file, c_ in tqdm(zip(f_names, classes.astype('str'))):\n",
    "        shutil.copy(str(root_path / file), str(root_path / c_))\n",
    "        \n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_memory_size(model):\n",
    "    total_ = 0\n",
    "    for k, v in model.state_dict().items():\n",
    "        print(f'name:{k} size:{v.size()} dtype:{v.dtype}')\n",
    "        total_ += v.numel()\n",
    "    print(f'Model size : {total_*4} byte -> {total_*4/1024**2} MiB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_value_frequencies(img_arr, dtype=int):\n",
    "  '''\n",
    "    img_arr = (N,H,W) or (H,W) \n",
    "    dtype = pixel values \n",
    "    counts unique pixel values of images\n",
    "  '''\n",
    "  arr = np.reshape(img_arr, -1)\n",
    "  uvals = np.unique(arr).astype(dtype)\n",
    "  uvals_dic = {}\n",
    "  \n",
    "  for u in list(uvals):\n",
    "    uvals_dic[u] = np.sum(arr==u)\n",
    "  return uvals_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_ratio_over_frequnecies(freq):\n",
    "  '''\n",
    "    # [2,3,4,5] -> [1/2, 1/3, 1/4, 1/5]\n",
    "  '''\n",
    "  return list(map(lambda x: 1/x, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optim, save_path, epoch, loss):\n",
    "  torch.save({\n",
    "        # 'model' : model,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss' : loss,\n",
    "        'optim_state_dict': optim.state_dict()\n",
    "    }, save_path)\n",
    "  print(f'model saved \\n {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model, map_location=None):\n",
    "  '''\n",
    "    args:\n",
    "      path : location to load model\n",
    "      model : model variable\n",
    "      map_location : device to load model\n",
    "    return:\n",
    "      model loaded weights from saved model\n",
    "  '''\n",
    "  load_model = torch.load(path, map_location=map_location)\n",
    "  model.load_state_dict(load_model['model_state_dict'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_imgs(imgs, title='img'):\n",
    "  '''\n",
    "      imgs : (N, H, W) or (N, C, H, W)\n",
    "  '''\n",
    "  plt.figure(figsize=(15,2)) \n",
    "  if np.ndim(imgs) == 2:\n",
    "    plt.imshow(imgs)\n",
    "\n",
    "  for i in range(len(imgs)):\n",
    "    plt.subplot(len(imgs)//2, 2, i+1)\n",
    "    plt.title(f'{i}th {title}')\n",
    "    if np.ndim(imgs) == 3:\n",
    "      plt.imshow(imgs[i], cmap='gray')\n",
    "    elif np.ndim(imgs) == 4:\n",
    "      plt.imshow(np.transpose(imgs[i], (2,3,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_weights_of_model(model):\n",
    "  l_p = sum(1 for x in model.parameters())\n",
    "  fg, axes = plt.subplots(l_p//5+1, 5, figsize=(15,15))\n",
    "  fg.tight_layout()\n",
    "\n",
    "  #torch.nn.utils.parameters_to_vector\n",
    "  for i,(n, p) in enumerate(model.named_parameters()):\n",
    "    ax = axes[i//5,i%5]\n",
    "    ax.set_title(n)\n",
    "    sns.distplot(p.detach().numpy(), ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_trained_mask(output, title='trained'):\n",
    "  \"\"\"\n",
    "    output : (N,C,H,W) display N trained masks \n",
    "  \"\"\"\n",
    "  output = torch.argmax(output, dim=1)\n",
    "  plt.figure(figsize=(15,2))\n",
    "  for i in range(len(output)):\n",
    "    plt.subplot(len(output)//2, 2, i+1)\n",
    "    plt.title(f'{i}th {title} mask')\n",
    "    plt.imshow(output[i], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights_by_pixel_frequencies(classId, EncodedPixels, img_size):\n",
    "  '''\n",
    "     img_size must be 1 dimension. (H*W)\n",
    "  '''\n",
    "  p_counts = np.zeros(len(classId.unique())+1)\n",
    "  \n",
    "  # counts total pixels of training image dataset\n",
    "  for c, e in zip(classId, EncodedPixels):\n",
    "    rlc = np.asarray(e.split(' '))\n",
    "    cls_pixels = sum(rlc[1::2].astype(int))\n",
    "    p_counts[c] += cls_pixels\n",
    "    p_counts[0] += img_size - cls_pixels \n",
    "\n",
    "  p_counts /= img_size\n",
    "  \n",
    "  return util.get_weights_ratio_over_frequnecies(p_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class2d_to_onehot(nn.Module):\n",
    "  def __init__(self, classes):\n",
    "    '''\n",
    "    args:\n",
    "      classes: [0,1,2,3... labels] labels must be integer\n",
    "      It will add channles of the number of labels to target \n",
    "    '''\n",
    "    super(class2d_to_onehot, self).__init__()\n",
    "    self.classes = torch.tensor(classes).unique()\n",
    "    \n",
    "  def forward(self, target):\n",
    "    '''\n",
    "      args: \n",
    "        target: (N,H,W), (H,W)\n",
    "      return:\n",
    "        (N,H,W)->(N,C,H,W)\n",
    "        (H,W)->(C,H,W)\n",
    "    ''' \n",
    "    ndims = len(target.size())\n",
    "\n",
    "    assert ndims == 2 or ndims == 3\n",
    "\n",
    "    if ndims == 2:\n",
    "      cls_stacks = torch.stack([(target==c).type(torch.float32) for c in self.classes], dim=0)\n",
    "    elif ndims == 3:\n",
    "      cls_stacks = torch.stack([(target==c).type(torch.float32) for c in self.classes], dim=1)\n",
    "\n",
    "    return cls_stacks\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook util.ipynb to script\n",
      "[NbConvertApp] Writing 4989 bytes to util.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  !jupyter nbconvert --to script util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
