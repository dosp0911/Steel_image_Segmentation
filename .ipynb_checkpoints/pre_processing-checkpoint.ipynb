{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import pathlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pre_process_img():\n",
    "    def __init__(self):\n",
    "        return \n",
    "        \n",
    "    def standardize(self, img_arr):\n",
    "        if not isinstance(img_arr, np.array):\n",
    "            raise TypeError('img_arr must be np.array type')\n",
    "        return img_arr / 255.0\n",
    "        \n",
    "        # h, w는 한쪽 부분에서 늘릴 길이\n",
    "    # data = [height, width, n_channels]\n",
    "    def overlap_tile(self, data, h, w):\n",
    "        if not np.ndim(data) == 3:\n",
    "            raise ValueError('dimension of the data have to be 3. [height, width, n_channels]')\n",
    "        old_h, old_w, _ = np.shape(data)\n",
    "        tmp_ = np.concatenate((data[:,(w-1)::-1,:], data, data[:,:(old_w-w-1):-1,:]), axis=1) # mirror 반사 모양으로 width 늘리기 \n",
    "        new_ = np.concatenate((tmp_[(h-1)::-1,:,:], tmp_, tmp_[:(old_h-h-1):-1,:,:]), axis=0) # mirror 반사 모양으로 height 늘리기\n",
    "        return new_\n",
    "\n",
    "        # size = (height,width) of img, \n",
    "    # return img with segmentation, 2d coordinates list\n",
    "    def decode_pixels_to_mask(self, size, encoded_p, mask_val=1):\n",
    "        mask_val = int(mask_val)\n",
    "        h, w, _ = size\n",
    "        p = np.array([int(m) for m in encoded_p.split(\" \")])\n",
    "        mask = np.zeros((h*w))\n",
    "\n",
    "        starts, lengths = p[::2], p[1::2]\n",
    "        for s, l in zip(starts, lengths):\n",
    "            mask[int(s-1):int(s+l-1)] = mask_val  ## masking\n",
    "\n",
    "        return mask.reshape(h,w, order='F')\n",
    "    \n",
    "        # color : which color to draw mask RGB\n",
    "    def apply_mask_to_img(self, img, mask, color, mask_val=1, alpha=0.5):\n",
    "        if not np.ndim(color):\n",
    "            raise ValueError('color must be 3dim.')\n",
    "        img[mask==mask_val] = ((1-alpha)*img[mask==mask_val] + alpha*np.array(color))\n",
    "        return img\n",
    "    \n",
    "    def crop_img(self, img_arr, h, w):\n",
    "        \"\"\"\n",
    "            img_arr = (h,w,c) or (h,w)\n",
    "            h , w = img size after cropping\n",
    "            \n",
    "        \"\"\"\n",
    "        dims = np.ndim(img_arr)\n",
    "        if dims is 2:\n",
    "            h_old, w_old = np.shape(img_arr)\n",
    "        elif dims is 3:\n",
    "            h_old, w_old, _ = np.shape(img_arr)\n",
    "        else:\n",
    "            raise ValueError('img shape does not fit.')\n",
    "            \n",
    "        x = math.ceil((h_old - h) / 2)\n",
    "        y = math.ceil((w_old - w) / 2)\n",
    "        \n",
    "        if dims is 2:\n",
    "            return img_arr[x:(x + h), y:(y + w)]\n",
    "        elif dims is 3:\n",
    "            return img_arr[x:(x + h), y:(y + w), :]\n",
    "    \n",
    "    def show_images_by_raw(self, img_arr, ncols, figsize=(20,10)):\n",
    "        if not np.ndim(img_arr)== 4:\n",
    "            raise ValueError('img_arr must be 4 dims.')\n",
    "        num = len(img_arr)\n",
    "        plt.figure(figsize=figsize)\n",
    "        for i in range(num):\n",
    "            plt.subplot(num/ncols, ncols, i+1)\n",
    "            plt.imshow(img_arr_s[i])\n",
    "    \n",
    "    def show_images(self, f_path, image_ids, n_col=2, figsize=(10,10)):\n",
    "\n",
    "        if isinstance(image_ids, (list, pd.Series)):\n",
    "            img_arr_list = []\n",
    "            n_imgs = len(image_ids)\n",
    "            fig, axes = plt.subplots(ncols=n_col, nrows=int(np.ceil(n_imgs/n_col)), figsize=figsize)\n",
    "\n",
    "            for i, img_id in enumerate(image_ids):\n",
    "                img_arr = plt.imread(f_path / img_id)\n",
    "                axes[i//n_col, i%n_col].imshow(img_arr)\n",
    "                img_arr_list.append(np.array(img_arr)) # np array 수정권한이 없어서 복사\n",
    "            return img_arr_list\n",
    "\n",
    "        else:\n",
    "            img_arr = plt.imread(f_path / image_ids)\n",
    "            plt.imshow(img_arr)\n",
    "            return np.arrary(img_arr)\n",
    "          \n",
    "    # img_arr shape = (H,W,C)\n",
    "    def rgb_to_gray(self, img_arr, new_axis=True):\n",
    "      if np.ndim(img_arr) != 3:\n",
    "        raise ValueError('img_arr must be 3 dim')\n",
    "      #  0.299 * R + 0.587 * G + 0.114 * B\n",
    "      gray_img = (0.299*img_arr[:,:,0] + 0.587 * img_arr[:,:,1] + 0.114 *img_arr[:,:,2])\n",
    "      if new_axis:\n",
    "        return gray_img[:,:,np.newaxis]\n",
    "      else:\n",
    "        return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pre_processing.ipynb to script\n",
      "[NbConvertApp] Writing 5302 bytes to pre_processing.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --to script pre_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util import csv_file_load\n",
    "# import pathlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# import torch\n",
    "# p = pathlib.Path('steel_images')\n",
    "# train_pd = csv_file_load(p/'train.csv')\n",
    "# pre = Pre_process_img()\n",
    "# img_arr = plt.imread(p/'train_images'/train_pd.ImageId[0] )\n",
    "\n",
    "# g = pre.rgb_to_gray(img_arr)\n",
    "\n",
    "# c = crop_feature_maps(torch.tensor(g[np.newaxis, :,:,:]).permute(0,3,1,2), 150,150)\n",
    "# plt.imshow(c[0].squeeze().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors_of_classes = [(0,0,0), (255,0,0), (0,255,0), (0,0,255), (255,0,255)]\n",
    "# masked_imgs_arr = []\n",
    "# for i,img in enumerate(img_arr_list):\n",
    "#     mask = p.decode_pixels_to_mask(np.shape(img), encoded_list[i])\n",
    "#     masked_img = p.apply_mask_to_img(img, mask, colors_of_classes[classes[i]])\n",
    "#     masked_imgs_arr.append(masked_img)\n",
    "    \n",
    "# fig, axes = plt.subplots(ncols=2, nrows=np.ceil(len(masked_imgs_arr)/2).astype(int), figsize=(30,15))\n",
    "# for i, m_img in enumerate(masked_imgs_arr):\n",
    "#     row, col = i//2, i%2\n",
    "#     axes[row, col].set_title(f'Class {classes[i]}')\n",
    "#     axes[row, col].imshow(m_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
