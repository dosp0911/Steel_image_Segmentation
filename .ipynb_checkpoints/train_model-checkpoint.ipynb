{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIh8jBqI1xNS"
   },
   "source": [
    "### TODO :\n",
    " - patch data\n",
    " - output mask size가 original image size 와 다른데 어떻게 같게 ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wE5P6a1S1xNU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# import import_ipynb\n",
    "from steel_dataset import Steel_dataset\n",
    "from model import U_net\n",
    "from util import csv_file_load\n",
    "import util\n",
    "from pre_processing import Pre_process_img\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30dyiPi21xNY"
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = pathlib.Path('steel_images')\n",
    "# ROOT_PATH = pathlib.Path('.')\n",
    "IMG_FILE_PATH = ROOT_PATH / 'train_images'\n",
    "TRAIN_FILE = ROOT_PATH / 'train.csv'\n",
    "CK_PATH = ROOT_PATH / 'checkpoints'\n",
    "LOG_PATH = ROOT_PATH / 'logs'\n",
    "\n",
    "SPILIT_RATIO = 0.8\n",
    "n_batch = 4\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0iE0WDk1xNb"
   },
   "outputs": [],
   "source": [
    "train_pd = csv_file_load(TRAIN_FILE)\n",
    "# train_pd.ClassId = 1\n",
    "train_idx = int(len(train_pd) * SPILIT_RATIO)\n",
    "\n",
    "val_pd = train_pd.iloc[train_idx:, :].reset_index(drop=True)\n",
    "train_pd = train_pd.iloc[:train_idx, :]\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tw7DCFse1xNe"
   },
   "outputs": [],
   "source": [
    "train_dataset = Steel_dataset(IMG_FILE_PATH, train_pd, out_size=(256, 1600))\n",
    "val_dataset = Steel_dataset(IMG_FILE_PATH, val_pd, out_size=(256, 1600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBIlR50x1xNj"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=n_batch, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=n_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBomvXDf1xNm"
   },
   "outputs": [],
   "source": [
    "u_net = U_net(n_classes=n_classes, in_channel= n_classes)\n",
    "# Initialize weights of U-net model with normal distribution std = sqrt(2/N), N = the number of incomding Nodes of one neuron\n",
    "# ex) 3x3 convd with 64 channels in previous layer -> N = 9 * 64 = 576 \n",
    "# for p in u_net.parameters():\n",
    "#   nn.init.normal_(p, std= math.sqrt(2/p[0].numel())) \n",
    "\n",
    "  \n",
    "# Xavier initialize   \n",
    "# for p in u_net.parameters():\n",
    "#   nn.init.xavier_normal_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del u_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaPZ0e9P1xNz"
   },
   "outputs": [],
   "source": [
    "def save_model(model, optim, save_path, epoch, loss):\n",
    "  torch.save({\n",
    "        'model' : model,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss' : loss,\n",
    "        'optim_state_dict': optim.state_dict()\n",
    "    }, save_path)\n",
    "  print(f'model saved \\n {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights_by_pixel_frequencies(classId, EncodedPixels, img_size):\n",
    "  '''\n",
    "     img_size must be 1 dimension. (H*W)\n",
    "  '''\n",
    "  p_counts = np.zeros(len(classId.unique())+1)\n",
    "  \n",
    "  # 0 is for background\n",
    "  # other than 0 is for foreground\n",
    "  u_classId = list(classId.unique())\n",
    "  u_classId.append(0)\n",
    "  \n",
    "  # counts total pixels of training image dataset\n",
    "  for c, e in zip(classId, EncodedPixels):\n",
    "    rlc = np.asarray(e.split(' '))\n",
    "    cls_pixels = sum(rlc[1::2].astype(int))\n",
    "    p_counts[c] += cls_pixels\n",
    "    p_counts[0] += img_size - cls_pixels \n",
    "  p_counts /= img_size\n",
    "    \n",
    "  return util.get_weights_ratio_over_frequnecies(p_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weight\n",
    " : class weight need to be adding the context(spatial variance) of images\n",
    "\n",
    "$ w~(c)~ = w~0~ + w~(context)~ $ \n",
    "\n",
    "$ Loss = -\\sum w(c) * p(x) * log(p(x)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6619,
     "status": "ok",
     "timestamp": 1585398218907,
     "user": {
      "displayName": "dongsup kim",
      "photoUrl": "",
      "userId": "13436176985677928979"
     },
     "user_tz": -540
    },
    "id": "pZMcMD3a1xN1",
    "outputId": "08df56bf-7f21-4909-849a-852de1eeb23f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00018669895161934006, 0.1309006771936889, 0.6234398782343988, 0.0039001194268747843, 0.01847140301219158]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weight = get_class_weights_by_pixel_frequencies(train_pd.ClassId, train_pd.EncodedPixels, 1600*256)\n",
    "\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoOTUujd1xN4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight= class_weight)\n",
    "optim = torch.optim.SGD(u_net.parameters(), momentum=0.99, lr=0.001)\n",
    "writer = SummaryWriter(LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Piq4v6ea5bYL"
   },
   "outputs": [],
   "source": [
    "train_len=len(train_dataset)\n",
    "val_len=len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10328353,
     "status": "error",
     "timestamp": 1585418499199,
     "user": {
      "displayName": "dongsup kim",
      "photoUrl": "",
      "userId": "13436176985677928979"
     },
     "user_tz": -540
    },
    "id": "W94eJagl1xN8",
    "outputId": "c190f1f8-1806-4120-c363-63b2077f06af"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "total_acc_train = 0.0\n",
    "total_acc_val = 0.0\n",
    "total_loss_val = 0.0\n",
    "total_loss_train = 0.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  total_acc_train = 0.0\n",
    "  total_acc_val = 0.0\n",
    "  total_loss_val = 0.0\n",
    "  total_loss_train = 0.0\n",
    "\n",
    "  for i, (x_, mask) in enumerate(train_dataloader):\n",
    "    x_ = x_.cuda()\n",
    "    mask = mask.cuda().long()\n",
    "    \n",
    "    optim.zero_grad()\n",
    "\n",
    "    out = u_net(x_)\n",
    "    loss_train = criterion(out, mask)\n",
    "    loss_train.backward()\n",
    "    optim.step()\n",
    "\n",
    "    total_acc_train += (torch.argmax(out, dim=1).squeeze() == mask).sum() / float(out.numel())\n",
    "    total_loss_train += loss_train\n",
    "\n",
    "    if i%100 == 0 :\n",
    "      writer.add_scalars('train',{'accuracy': total_acc_train/i, 'loss' : total_loss_train})\n",
    "      print(f'epoch:{epoch} train batch : {i/train_len * 100}% ---- \\n train_loss:{total_loss_train / i} \\\n",
    "                        train_accuracy:{total_acc_train / i }')\n",
    "\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    for j, (val_x, val_mask) in enumerate(val_dataloader):\n",
    "      val_x = val_x.cuda()\n",
    "      val_mask = val_mask.cuda().long()\n",
    "      out_val = u_net(val_x)\n",
    "      loss_val = criterion(out_val, val_mask)\n",
    "\n",
    "      total_acc_val += (torch.argmax(out_val, dim=1).squeeze() == val_mask).sum() / float(out_val.numel())\n",
    "      total_loss_val += loss_val\n",
    "\n",
    "      if j%100 == 0:\n",
    "        print(f'epoch:{epoch} val_batch : {j/val_len * 100}% ---- \\n val_loss:{total_loss_val / j} \\\n",
    "                        val_accuracy:{total_acc_val / j}')\n",
    "      if j == val_len:\n",
    "        # display output images of each classes\n",
    "        for k in range(len(n_classes)):\n",
    "          g = make_grid(out_val[:,k,:,:].squeeze(dim=1))\n",
    "          writer.add_images(f'val_output class{k+1}', g)\n",
    "        # display class names of each images\n",
    "        val_cls = [int(val_mask[l].unique()[1]) for l in range(len(val_mask))]\n",
    "        m_g = mask_grid(val_mask.unsqueeze(dim=1))\n",
    "        writer.add_images(f'val_mask class {val_cls})', m_g.squeeze(dim=1), dataformats='HW')\n",
    "        \n",
    "  writer.add_scalars('val',{'accuracy': total_acc_val/val_len, 'loss': total_loss_val}) \n",
    "  print(f'epoch:{epoch} ended. \\n -- total_val_loss:{total_loss_val} total_val_accuracy:{total_acc_val}')        \n",
    "    \n",
    "  save_model(u_net, optim, f'u_net_{epoch}e_{int(total_loss_val)}l.pt', epoch, total_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : 1784 y:890.0\n",
      "x : 890.0 y:443.0\n",
      "x : 443.0 y:219.5\n",
      "x : 219.5 y:107.75\n",
      "x : 107.75 y:207.5\n",
      "x : 207.5 y:407.0\n",
      "x : 407.0 y:806.0\n",
      "x : 806.0 y:1604.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1600.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "j = 3\n",
    "def c(x):\n",
    "  global i\n",
    "  y = (x-4)/2\n",
    "  print(f'x : {x} y:{y}')\n",
    "  if i != 0:\n",
    "    i -= 1\n",
    "    return c(y)\n",
    "  else:\n",
    "    return y\n",
    "  \n",
    "def d(x):\n",
    "  global j\n",
    "  y = (x-4)*2\n",
    "  print(f'x : {x} y:{y}')\n",
    "  if j != 0:\n",
    "    j -= 1\n",
    "    return d(y)\n",
    "  else:\n",
    "    return y\n",
    "  \n",
    "d(c(1784))-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 624, 1968])\n",
      "torch.Size([4, 1, 624, 1968])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11222138880 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f7c0237bcbcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Steel_image_Segmentation\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_x)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;31m# input_x has to be shape of (n_batches, n_channels, height, width)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mo_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontracting_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[0mo_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpansive_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mo_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Steel_image_Segmentation\\model.py\u001b[0m in \u001b[0;36mcontracting_path\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcontracting_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_layer1_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_layer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_layer2_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_max_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_layer1_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_layer2_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11222138880 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "a = iter(train_dataloader).next()\n",
    "print(a[0].size())\n",
    "b = u_net(a[0].float())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
